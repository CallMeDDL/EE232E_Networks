\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Reinforcement Learning (RL)}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Optimal policy learning using RL algorithms}{1}{subsection.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Heat map of reward function $1$\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:hm_reward_1}{{1}{1}{Heat map of reward function $1$\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Heat map of reward function $2$\relax }}{1}{figure.caption.1}}
\newlabel{fig:hm_reward_2}{{2}{1}{Heat map of reward function $2$\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The optimal state value with reward function $1$\relax }}{2}{figure.caption.2}}
\newlabel{fig:optimal_state_value_01}{{3}{2}{The optimal state value with reward function $1$\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Heat map of optimal state values with reward function $1$\relax }}{2}{figure.caption.2}}
\newlabel{fig:hm_opt_state_value_01}{{4}{2}{Heat map of optimal state values with reward function $1$\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Optimal actions with reward function $1$\relax }}{3}{figure.caption.3}}
\newlabel{fig:opt_action_01}{{5}{3}{Optimal actions with reward function $1$\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The optimal state value with reward function $2$\relax }}{3}{figure.caption.3}}
\newlabel{fig:opt_state_value_02}{{6}{3}{The optimal state value with reward function $2$\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Heat map of optimal state values with reward function $2$\relax }}{4}{figure.caption.4}}
\newlabel{fig:hm_opt_state_value_02}{{7}{4}{Heat map of optimal state values with reward function $2$\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Optimal actions with reward function $2$\relax }}{4}{figure.caption.4}}
\newlabel{fig:opt_actions_02}{{8}{4}{Optimal actions with reward function $2$\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Inverse Reinforcement Learning (IRL)}{4}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}IRL algorithm}{4}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Performance measure}{5}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The plot of Accuracy with $\lambda $\relax }}{6}{figure.caption.5}}
\newlabel{3_1}{{9}{6}{The plot of Accuracy with $\lambda $\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Heat map of ground truth reward\relax }}{6}{figure.caption.6}}
\newlabel{3_2_1}{{10}{6}{Heat map of ground truth reward\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Heat map of extracted reward\relax }}{6}{figure.caption.6}}
\newlabel{3_2}{{11}{6}{Heat map of extracted reward\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The heat map of optimal values\relax }}{7}{figure.caption.7}}
\newlabel{3_3}{{12}{7}{The heat map of optimal values\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The arrows plot of optimal policy\relax }}{7}{figure.caption.7}}
\newlabel{3_4}{{13}{7}{The arrows plot of optimal policy\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The plot of Accuracy with $\lambda $\relax }}{8}{figure.caption.8}}
\newlabel{4_1}{{14}{8}{The plot of Accuracy with $\lambda $\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Heat map of ground truth reward\relax }}{8}{figure.caption.9}}
\newlabel{4_2_1}{{15}{8}{Heat map of ground truth reward\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Heat map of extracted reward\relax }}{8}{figure.caption.9}}
\newlabel{4_2}{{16}{8}{Heat map of extracted reward\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces The heat map of optimal values\relax }}{9}{figure.caption.10}}
\newlabel{4_3}{{17}{9}{The heat map of optimal values\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The arrows plot of optimal policy\relax }}{9}{figure.caption.10}}
\newlabel{4_4}{{18}{9}{The arrows plot of optimal policy\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces The plot of new optimal policy\relax }}{10}{figure.caption.11}}
\newlabel{4_5}{{19}{10}{The plot of new optimal policy\relax }{figure.caption.11}{}}
